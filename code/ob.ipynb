{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_timestamp(timestamp):\n",
    "    return datetime.utcfromtimestamp(timestamp / 1000).strftime('%Y-%m-%d %H:%M:%S UTC')\n",
    "\n",
    "def get_current_time(insType):\n",
    "    datetime_str  = datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')\n",
    "    if insType == 'f':\n",
    "        return datetime_str\n",
    "    parsed_datetime = datetime.strptime(datetime_str, '%Y-%m-%d %H:%M:%S UTC')\n",
    "    if insType == 's':\n",
    "        return parsed_datetime.second \n",
    "    if insType == 'm':\n",
    "        return parsed_datetime.minute\n",
    "    if insType == 'h':\n",
    "        return parsed_datetime.hour\n",
    "    if insType == 'd':\n",
    "        return parsed_datetime.day\n",
    "        \n",
    "def calculate_percentage_difference(old_value, new_value):\n",
    "    try:\n",
    "        percentage_difference = ((new_value - old_value) / abs(old_value)) * 100\n",
    "        return percentage_difference\n",
    "    except ZeroDivisionError:\n",
    "        return float('inf')\n",
    "\n",
    "def get_bucket_list(current_price, bucket_range, n_buckets):\n",
    "    \"\"\"\n",
    "        For initialization of buckets\n",
    "    \"\"\"\n",
    "    rounded_current_price = round(current_price / 20) * 20\n",
    "    asbp = rounded_current_price + (bucket_range * n_buckets) + 1\n",
    "    bsbp = rounded_current_price - (bucket_range * n_buckets) - 1\n",
    "    bid_buckets = [i for i in range(rounded_current_price, bsbp, -bucket_range)]\n",
    "    bid_buckets = [[b, a] for a, b in zip(bid_buckets, bid_buckets[1:])]\n",
    "    ask_buckets = [i for i in range(rounded_current_price, asbp, bucket_range)]\n",
    "    ask_buckets = [[a, b] for a, b in zip(ask_buckets, ask_buckets[1:])]\n",
    "    full = sorted(bid_buckets + ask_buckets)\n",
    "    return full\n",
    "\n",
    "\n",
    "def create_data_frame(dftype, bucker_list):                                \n",
    "    \"\"\"\n",
    "        dftype: sec, min, h, 4h, d\n",
    "        - sec: seconds in a minute\n",
    "        - min: minutes in a day\n",
    "        - h: 2000 hours\n",
    "        - 4h: 1000 hours\n",
    "        - d: 365\n",
    "    \"\"\"\n",
    "    if dftype == 'sec':      \n",
    "        r = list(range(0, 60, 1))   # Valid range [0-59]    # Seconds in a minute\n",
    "    if dftype == 'min':\n",
    "        r = list(range(0, 10080, 1)) # Valid range [0-59]   # Minutes in a week\n",
    "    if dftype == 'h':\n",
    "        r = list(range(0, 8760, 1)) # Valid range [0-23]    # Hours in a year\n",
    "    columns = [\"_\".join([str(x[0]), str(x[1])]) for x in bucker_list]\n",
    "    df = pd.DataFrame(index=r, columns=['price', 'volume'] + columns)\n",
    "    return df\n",
    "\n",
    "# ####################################\n",
    "\n",
    "# def get_binance_books(limit=5000):\n",
    "#     \"\"\"\n",
    "#       If there are no 5000 book records, we will try with lesser amount of records\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         conn = http.client.HTTPSConnection(\"api.binance.com\")\n",
    "#         conn.request(\"GET\", f\"/api/v3/depth?symbol=BTCUSDT&limit={limit}\")\n",
    "#         b = json.loads(conn.getresponse().read().decode(\"utf-8\"))\n",
    "#     except:\n",
    "#         limit = limit-100\n",
    "#         get_binance_books(limit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = bookFeatures('binance', 'futures', 'btc_usdt', 43000, 10, 1)\n",
    "for i in range(23):\n",
    "  try:\n",
    "    data = json.load(open(f'/content/SatoshiVault/data/trades_{i}.json', 'r'))\n",
    "    print(data)\n",
    "    books.dfs_input_trades(data)\n",
    "  except:\n",
    "    continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bookFeatures:\n",
    "\n",
    "    def __init__(self, exchange, insType, symbol, start_price, bucket_range, n_buckets):\n",
    "        # Identification\n",
    "        self.exchange = exchange\n",
    "        self.insType = insType\n",
    "        self.symbol = symbol\n",
    "        # Tracking\n",
    "        self.current_price = start_price\n",
    "        self.current_time = get_current_time('f')\n",
    "        # Bucket ranges\n",
    "        self.bucket_range = bucket_range\n",
    "        self.current_buckets_dfs = get_bucket_list(start_price, bucket_range, n_buckets)\n",
    "        self.current_buckets_dfm = get_bucket_list(start_price, bucket_range, n_buckets)\n",
    "        # Books frames\n",
    "        self.dfs_books = create_data_frame('sec', self.current_buckets_dfs)\n",
    "        self.dfm_books = create_data_frame('min', self.current_buckets_dfs)\n",
    "        # Trades frames\n",
    "        self.dfs_trades = create_data_frame('sec', self.current_buckets_dfs)\n",
    "        self.dfm_trades = create_data_frame('min', self.current_buckets_dfs)\n",
    "        # Canceled books frames\n",
    "        self.dfs_canc_books = create_data_frame('sec', self.current_buckets_dfs)\n",
    "        self.dfm_canc_books = create_data_frame('min', self.current_buckets_dfs)\n",
    "        # Reinforced books frames\n",
    "        self.dfs_rein_books = create_data_frame('sec', self.current_buckets_dfs)\n",
    "        self.dfm_rein_books = create_data_frame('min', self.current_buckets_dfs)\n",
    "        # Open interest\n",
    "\n",
    "        # Long Short positions\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        # Exchanges objects namings\n",
    "        self.asks = ['asks', 'ask', 'a']\n",
    "        self.bids = ['bids', 'bid', 'b']\n",
    "        self.price = ['price', 'p']\n",
    "        self.volume = ['volume', 'quantity', 'v', 'q']\n",
    "\n",
    "    def generate_features():\n",
    "        # Generate yours features here\n",
    "        pass\n",
    "\n",
    "    def dfs_to_dfm(self):\n",
    "\n",
    "        current_second = get_current_time('s')\n",
    "        current_minute = get_current_time('m')\n",
    "        \n",
    "        if current_second == 59:\n",
    "\n",
    "          # dfb\n",
    "          # price\n",
    "          # price Variance\n",
    "          # Total Volume ---- Taken from MarketTrades\n",
    "          # Last_books\n",
    "\n",
    "          # dft\n",
    "          # price\n",
    "          # Total Volume \n",
    "          # sum of all trades\n",
    "          \n",
    "          # dfc\n",
    "          # Total Volume of canceled\n",
    "          # price\n",
    "          # sum of all cancled\n",
    "          \n",
    "          # dfr\n",
    "          # Total Volume of reinforced\n",
    "          # price\n",
    "          # sum of all reinforced\n",
    "\n",
    "        pass\n",
    "\n",
    "\n",
    "    def dfs_input_canceled_reinforced(self):\n",
    "        \"\"\"\n",
    "            Periodic task, must be done every minute\n",
    "        \"\"\"\n",
    "        # Calculate canceled books\n",
    "        current_second = get_current_time('s')\n",
    "        previous_column = current_second -1\n",
    "        if current_second == 0:\n",
    "            previous_column = 59\n",
    "        # Calculates canceled or reinforced books over certain timestamps\n",
    "        D = (self.dfs_books.iloc[current_second, :] + self.dfs_trades.iloc[current_second, :]) - (self.dfs_books.iloc[previous_column, :] + self.dfs_trades.iloc[previous_column, :])\n",
    "        self.dfs_canc_books.iloc[current_second, :] = D.clip(lower=0)\n",
    "        self.dfs_rein_books.iloc[current_second, :] = D.clip(upper=0).abs()\n",
    "\n",
    "\n",
    "    def dfs_input_trades(self, trade):                                            # Works fine  # FIX when inputing new data to dfm The last raw is being deleted\n",
    "        \"\"\" \n",
    "            Inputs price, volume(amount) and trades into dfs_trades frame\n",
    "            Inputs price into dfs_books\n",
    "        \"\"\"\n",
    "        current_second = get_current_time('s')\n",
    "        current_price = float(trade['p'])\n",
    "        print(current_price)\n",
    "        amount = float(trade['q'])\n",
    "        located_bucket = self.locate_bucket(current_price, self.current_buckets_dfs)\n",
    "\n",
    "        self.dfs_books.loc[current_second, 'price'] = current_price\n",
    "        self.dfs_trades.loc[current_second, 'price'] = current_price\n",
    "        self.dfs_canc_books.loc[current_second, 'price'] = current_price\n",
    "\n",
    "        # If the bucket exists\n",
    "        if located_bucket != None:\n",
    "            col_name = \"_\".join([str(located_bucket[0]), str(located_bucket[1])])\n",
    "            if np.isnan(self.dfs_trades.at[current_second, col_name]) == True:\n",
    "                self.dfs_trades.loc[current_second, col_name] =  amount\n",
    "            else: \n",
    "                self.dfs_trades.loc[current_second, col_name] = self.dfs_trades.at[current_second, col_name] + amount\n",
    "        # if the bucket doesnt exist\n",
    "        if located_bucket == None:\n",
    "          # Makes new buckets\n",
    "          new_buckets = self.get_new_buckets(current_price, self.current_buckets_dfs)\n",
    "          self.current_buckets_dfs = sorted(self.current_buckets_dfs + new_buckets)\n",
    "          new_names = [\"_\".join([str(x[0]), str(x[1])]) for x in new_buckets]\n",
    "          for name in new_names:\n",
    "              self.dfs_trades[name] = np.nan\n",
    "              self.dfs_books[name] = np.nan\n",
    "              self.dfs_canc[name] = np.nan\n",
    "              self.dfs_rein[name] = np.nan\n",
    "          # Finaly input values\n",
    "          l = self.locate_bucket(current_price, self.current_buckets_dfs)\n",
    "          col_name = \"_\".join([str(l[0]), str(l[1])])\n",
    "          if np.isnan(self.dfs_trades.at[current_second, col_name]) == True:\n",
    "              self.dfs_trades.loc[current_second, col_name] =  amount\n",
    "          else: \n",
    "              self.dfs_trades.loc[current_second, col_name] = self.dfs_trades.at[current_second, col_name] + amount\n",
    "\n",
    "        # Make sure the next row is empy\n",
    "        s = get_current_time('s')\n",
    "        if s == 59:\n",
    "          s = 0\n",
    "        dfs_trades.iloc[s+1, :] = np.nan\n",
    "\n",
    "\n",
    "    def dfs_input_books(self, books : dict):\n",
    "        \"\"\"\n",
    "            Updates dfs bids and asks\n",
    "        \"\"\"\n",
    "        current_second = get_current_time('s')\n",
    "        self.dfs_input_books(books['asks'], current_second)\n",
    "        self.dfs_input_books(books['bids'], current_second)\n",
    "\n",
    "        # Make sure the next row is empy\n",
    "        s = get_current_time('s')\n",
    "        if s == 59:\n",
    "          s = 0\n",
    "        dfs_books.iloc[s+1, :] = np.nan\n",
    "\n",
    "    def dfs_input_books_helper(self, books : list, current_second):                         # Works Fine # Works fine  # FIX when inputing new data to dfm. The last raw delete, which is not suppoused to be\n",
    "        \"\"\"\n",
    "            Iputs books in dfs dataframe\n",
    "            Creates new_buckets if necessary\n",
    "            Updates current buckets dfs\n",
    "        \"\"\"\n",
    "        for book in books:\n",
    "            col = float(book[0])\n",
    "            amount = float(book[1])\n",
    "            located_bucket = self.locate_bucket(col, self.current_buckets_dfs)\n",
    "            # If the bucket exists\n",
    "            if located_bucket != None:\n",
    "                col_name = \"_\".join([str(located_bucket[0]), str(located_bucket[1])])\n",
    "                if np.isnan(self.dfs_books.at[current_second, col_name]) == True:\n",
    "                    self.dfs_books.loc[current_second, col_name] =  amount\n",
    "                else: \n",
    "                    self.dfs_books.loc[current_second, col_name] = self.dfs_books.at[current_second, col_name] + amount\n",
    "            # If the bucket doesn't exist\n",
    "            if located_bucket == None:\n",
    "                # Makes new buckets\n",
    "                new_buckets = self.get_new_buckets(col, self.current_buckets_dfs)\n",
    "                self.current_buckets_dfs = sorted(self.current_buckets_dfs + new_buckets)\n",
    "                new_names = [\"_\".join([str(x[0]), str(x[1])]) for x in new_buckets]\n",
    "                for name in new_names:\n",
    "                    self.dfs_trades[name] = np.nan\n",
    "                    self.dfs_books[name] = np.nan\n",
    "                    self.dfs_canc[name] = np.nan\n",
    "                    self.dfs_rein[name] = np.nan\n",
    "                # Finaly input values\n",
    "                l = self.locate_bucket(col, self.current_buckets_dfs)\n",
    "                col_name = \"_\".join([str(l[0]), str(l[1])])\n",
    "                if np.isnan(self.dfs_books.at[current_second, col_name]) == True:\n",
    "                    self.dfs_books.loc[current_second, col_name] =  amount\n",
    "                else: \n",
    "                    self.dfs_books.loc[current_second, col_name] = self.dfs_books.at[current_second, col_name] + amount\n",
    "\n",
    "\n",
    "    def locate_bucket(self, value: float, ranges : list):               # Works well\n",
    "        for index, (start, end) in enumerate(ranges):\n",
    "            if start <= value < end:\n",
    "                return ranges[index]\n",
    "        return None\n",
    "      \n",
    "            \n",
    "    def get_new_buckets(self, value : float, current_buckets : list):    # Works fine\n",
    "        step = self.bucket_range\n",
    "        mmax = max(current_buckets)[1]\n",
    "        mmin = min(current_buckets)[0]\n",
    "        l = []\n",
    "        if value > mmax or value == mmax:\n",
    "            rounded_value = int(math.ceil(value / step) * step)\n",
    "            for v in range(mmax, rounded_value, step):\n",
    "                l.append([v, v+step ])\n",
    "            if rounded_value == value and value == mmax:\n",
    "                l.append([int(value), int(value+step)])\n",
    "        if value < mmin:\n",
    "            rounded_value = max(0, int(value / step) * step)\n",
    "            for v in range(rounded_value, mmin, step):\n",
    "                l.append([v, v+step ])\n",
    "        return l    \n",
    "\n",
    "    def dfs_remove_empty_columns(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # # REDO\n",
    "        # # If all of the certain buckets cointain the same NULLS - remove\n",
    "        # # dfs\n",
    "        # empty_columns = [[int(x.split('_')[0]), int(x.split('_')[1])]for x in self.dfs_books.columns[self.dfs_books.isnull().all()].tolist()]\n",
    "        # self.current_buckets_dfs = [x for x in self.current_buckets_dfs if x not in empty_columns]\n",
    "        # self.dfs_books.dropna(axis=1, how='all')\n",
    "        # self.dfs_canc_books(axis=1, how='all')\n",
    "        # # dfm\n",
    "        # empty_columns = [[int(x.split('_')[0]), int(x.split('_')[1])]for x in self.dfm_books.columns[self.dfm_books.isnull().all()].tolist()]\n",
    "        # self.current_buckets_dfm = [x for x in self.current_buckets_dfm if x not in empty_columns]\n",
    "        # self.dfm_books.dropna(axis=1, how='all')\n",
    "        # self.dfm_canc_books(axis=1, how='all')\n",
    "        # # dfh\n",
    "        # empty_columns = [[int(x.split('_')[0]), int(x.split('_')[1])]for x in self.dfh_books.columns[self.dfh_books.isnull().all()].tolist()]\n",
    "        # self.current_buckets_dfh = [x for x in self.current_buckets_dfh if x not in empty_columns]\n",
    "        # self.dfh_books.dropna(axis=1, how='all')\n",
    "        # self.dfh_canc_books(axis=1, how='all')\n",
    "        # # dfd\n",
    "        # empty_columns = [[int(x.split('_')[0]), int(x.split('_')[1])]for x in self.dfd_books.columns[self.dfd_books.isnull().all()].tolist()]\n",
    "        # self.current_buckets_dfd = [x for x in self.current_buckets_dfd if x not in empty_columns]\n",
    "        # self.dfd_books.dropna(axis=1, how='all')\n",
    "        # self.dfd_canc_books(axis=1, how='all')\n",
    "        # # Remove buckets from \n",
    "        # self.bucket_rangebb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open('/content/SatoshiVault/data/bbooks.json', 'r'))\n",
    "books = bookFeatures('binance', 'futures', 'btc_usdt', 43000, 10, 1)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#books.input_book_dfs(data)\n",
    "for _ in range(60):\n",
    "  books.dfs_books_process(data)\n",
    "  time.sleep(1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Elapsed_time\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(23):\n",
    "  try:\n",
    "    data = json.load(open(f'/content/SatoshiVault/data/trades_{i}.json', 'r'))\n",
    "    print(data)\n",
    "    books.dfs_input_trades(data)\n",
    "  except:\n",
    "    continue\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
