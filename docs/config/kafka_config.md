# Kafka Configuration Parameters

This document explains various Kafka configuration parameters with typical settings and links to Kafka documentation for further reading.

## Message Parameters

### `message.max.bytes`
- **Description**: Maximum size of a message that the broker will accept.
- **Typical Setting**: Larger than your largest expected message size (e.g., 1MB if expecting large messages).
- **Documentation**: [Kafka Documentation](https://kafka.apache.org/documentation/#brokerconfigs_message.max.bytes)

### `replica.fetch.max.bytes`
- **Description**: Maximum number of bytes fetch requests are allowed to fetch from a single partition.
- **Typical Setting**: Same or slightly larger than `message.max.bytes`.
- **Documentation**: [Kafka Documentation](https://kafka.apache.org/documentation/#brokerconfigs_replica.fetch.max.bytes)

### `fetch.message.max.bytes`
- **Description**: Maximum number of bytes fetch requests are allowed to fetch from a single partition. This must be at least as large as the largest message you want to fetch.
- **Typical Setting**: Match with `message.max.bytes`.
- **Documentation**: [Kafka Documentation](https://kafka.apache.org/documentation/#consumerconfigs_fetch.message.max.bytes)

## Thread Parameters

### `num.network.threads`
- **Description**: The number of threads that the server uses for processing requests, which are received over the network.
- **Typical Setting**: Depends on your server's hardware, but starting with a value equal to the number of cores is a good approach.
- **Documentation**: [Kafka Documentation](https://kafka.apache.org/documentation/#brokerconfigs_num.network.threads)

### `num.io.threads`
- **Description**: The number of threads that perform disk I/O operations in the broker.
- **Typical Setting**: Equal to or greater than the number of storage devices.
- **Documentation**: [Kafka Documentation](https://kafka.apache.org/documentation/#brokerconfigs_num.io.threads)

## Socket Parameters

### `socket.receive.buffer.bytes`
- **Description**: The receive buffer (`SO_RCVBUF`) used by the network sockets.
- **Typical Setting**: Increase if noticing network issues, typical values are 102400 (100KB) to 204800 (200KB).
- **Documentation**: [Kafka Documentation](https://kafka.apache.org/documentation/#brokerconfigs_socket.receive.buffer.bytes)

### `socket.send.buffer.bytes`
- **Description**: The send buffer (`SO_SNDBUF`) used by the network sockets.
- **Typical Setting**: Same as `socket.receive.buffer.bytes`.
- **Documentation**: [Kafka Documentation](https://kafka.apache.org/documentation/#brokerconfigs_socket.send.buffer.bytes)

## Queue Parameters

### `queued.max.request.bytes`
- **Description**: The maximum number of bytes in the request queue. A large request queue can handle a high volume of requests but may use more memory.
- **Typical Setting**: Adjust based on memory availability and load.
- **Documentation**: [Kafka Documentation](https://kafka.apache.org/documentation/#brokerconfigs_queued.max.request.bytes)

## Producer Parameters

### `max.request.size`
- **Description**: Maximum size of a request that the producer can send.
- **Typical Setting**: Match or exceed `message.max.bytes`.
- **Documentation**: [Kafka Documentation](https://kafka.apache.org/documentation/#producerconfigs_max.request.size)

### `buffer.memory`
- **Description**: Total bytes of memory the producer can use to buffer records waiting to be sent to the server.
- **Typical Setting**: Higher values can handle more records held during high traffic bursts.
- **Documentation**: [Kafka Documentation](https://kafka.apache.org/documentation/#producerconfigs_buffer.memory)

### `compression.type`
- **Description**: Specify the compression type for all data generated by the producer. Options include none, gzip, snappy, lz4, or zstd.
- **Typical Setting**: gzip or snappy for a balance between compression rate and CPU usage.
- **Documentation**: [Kafka Documentation](https://kafka.apache.org/documentation/#producerconfigs_compression.type)

### `linger.ms`
- **Description**: The producer will wait this long before sending records if the batch isn't filled.
- **Typical Setting**: Increases batch size and throughput at the cost of latency.
- **Documentation**: [Kafka Documentation](https://kafka.apache.org/documentation/#producerconfigs_linger.ms)

### `batch.size`
- **Description**: Maximum number of bytes that will be included in a batch of messages.
- **Typical Setting**: Increase to maximize throughput, especially if you are sending large messages.
- **Documentation**: [Kafka Documentation](https://kafka.apache.org/documentation/#producerconfigs_batch.size)

### `acks`
- **Description**: The number of acknowledgments the producer requires from brokers.
- **Typical Setting**: all for ensuring full durability of records.
- **Documentation**: [Kafka Documentation](https://kafka.apache.org/documentation/#producerconfigs_acks)

### `retry.backoff.ms`
- **Description**: The amount of time to wait before attempting to retry a failed produce request.
- **Typical Setting**: Adjust based on your application's tolerance for retries.
- **Documentation**: [Kafka Documentation](https://kafka.apache.org/documentation/#producerconfigs_retry.backoff.ms)